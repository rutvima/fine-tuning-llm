# Fine Tuning LLM

Over three weeks, this course guides you through the art and science of fine‑tuning large language models for real‑world applications. 
- **Week 1** introduces Transformer architecture, contrasts pretrained vs. fine‑tuned models, and surveys frameworks like Hugging Face’s Trainer. You’ll benchmark encoder and decoder models on the Financial PhraseBank dataset, learning to assess accuracy, robustness and domain adaptation.  
- In **Week 2**, you’ll dive deeper into encoder architectures—mastering BERT and DistilBERT fine‑tuning for natural language inference and sentiment analysis. You’ll deploy your distilled financial sentiment model to the Hugging Face Hub, gaining hands‑on MLOps experience with versioning, packaging and sharing your work. 
- **Week 3** explores decoder models, parameter‑efficient techniques (LoRA, QLoRA) and Reinforcement Learning from Human Feedback to enhance generation quality. You’ll apply these methods to fine‑tune Microsoft’s Phi‑1.5 on SciTLDR for extreme summarization of scientific papers, optimizing GPU utilization and conserving compute.  

These hands‑on projects and techniques ensure you can craft, evaluate and refine LLMs cost‑effectively, turning experimental prototypes into robust, shareable tools. You’ll finish equipped to spearhead NLP initiatives—designing, fine‑tuning and deploying LLMs that deliver specialized, high‑impact solutions across finance, research and beyond.  

