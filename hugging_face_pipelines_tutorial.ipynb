{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Hugging Face ü§ó [Transformers](https://github.com/huggingface/transformers) provide access to state-of-the-art pre-trained NLP models and pipelines to turn raw text into useful results. Many state of the art deep learning architectures have been published and made available from Hugging Face model [hub](https://huggingface.co/models).\n",
        "\n",
        "In this tutorial, you will run the following NLP tasks using Hugging Face Pipelines. Objective of this tutorial is for you to get familiar with different NLP tasks and the navigating Hugging Face Models.\n",
        "- Text Classification\n",
        "  - Sentiment Analysis\n",
        "  - Natural Language Inference\n",
        "  - Question Natural Language Inference\n",
        "  - Quora Question Pair\n",
        "  - Grammatical Correctness\n",
        "- Zero-shot classification\n",
        "- Token Classification\n",
        "  - Named Entity Recognition (NER)\n",
        "  - Part of Speech Tagging (POS)\n",
        "- Translation\n",
        "- Summarization\n",
        "- Question Answering\n",
        "- Text Generation\n",
        "  - In-context Learning\n"
      ],
      "metadata": {
        "id": "08bjX05qiVwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] datasets emoji==0.6.0 sentencepiece"
      ],
      "metadata": {
        "id": "25xQ0P20ox1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import pipeline"
      ],
      "metadata": {
        "id": "RysDe1Ldpms3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from rich import print"
      ],
      "metadata": {
        "id": "aMw80Hs6pmFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text classification\n",
        "\n",
        "Text classification involves assigning a label or category to a given text. Common use cases include sentiment analysis, natural language inference, and the assessment of grammatical correctness."
      ],
      "metadata": {
        "id": "8uTwSYtqjYXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis\n",
        "\n",
        "Sentiment analysis is a type of natural language processing technique that involves analyzing a piece of text to determine the sentiment or emotion expressed within it. It can be used to classify a text as positive, negative, or neutral, and has a wide range of applications in fields such as marketing, customer service, and political analysis."
      ],
      "metadata": {
        "id": "fFfuHNm-jez0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_classification_pipeline = pipeline(\"text-classification\")\n",
        "\n",
        "inputs = [\"I love how amazingly simple ML has become!\",\n",
        "          \"I hate doing mundane and thankless tasks. ‚òπÔ∏è\"]\n",
        "\n",
        "results = text_classification_pipeline(inputs)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "aERX1kAsqswR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specific model\n",
        "\n",
        "Default model for text classification is distilbert-base-uncased-finetuned-sst-2-english. If you want to use one of the over 19,000 models available on Hugging Face, include the name of the desired model in the pipeline."
      ],
      "metadata": {
        "id": "lSeDnKdCrHYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-classification\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
        "pipe([\"I love how amazingly simple ML has become!\", \"I hate doing mundane and thankless tasks. ‚òπÔ∏è\"])"
      ],
      "metadata": {
        "id": "bRdooLwWraUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Industry specific model\n",
        "\n",
        "By selecting a model that has been specifically designed for a particular industry, you can achieve more accurate and relevant text classification. An example of such a model is FinBERT, a pre-trained NLP model that has been optimized for analyzing sentiment in financial text. FinBERT was created by training the BERT language model on a large financial corpus, and fine-tuning it to specifically classify financial sentiment. When using FinBERT, the model will provide softmax outputs for three different labels: positive, negative, or neutral."
      ],
      "metadata": {
        "id": "BA3B3qJkj7xQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-classification\",model=\"ProsusAI/finbert\")\n",
        "pipe([\"Stocks rallied and the British pound gained.\",\"Stocks making the biggest moves midday: Nvidia, Palantir and more\"])"
      ],
      "metadata": {
        "id": "ro6gCFPet7F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Inference (NLI)\n",
        "NLI, or Natural Language Inference, is a type of model that determines the relationship between two texts. The model takes a premise and a hypothesis as inputs and returns a class, which can be one of three types:\n",
        "\n",
        "* Entailment: This means that the hypothesis is true based on the premise.\n",
        "* Contradiction: This means that the hypothesis is false based on the premise.\n",
        "* Neutral: This means that there is no relationship between the hypothesis and the premise.\n",
        "\n",
        "The GLUE dataset is the benchmark dataset for evaluating NLI models. There are different variants of NLI models, such as Multi-Genre NLI, Question NLI, and Winograd NLI. If you want to use an NLI model, you can find them on the ü§ó Hugging Face model hub. Look for models with \"mnli\".\n",
        "\n",
        "Below Example:\n",
        "```\n",
        "Premise: Soccer game with multiple males playing.\n",
        "Hypothesis: Some men are playing a sport.\n",
        "Label: Entailment\n",
        "```"
      ],
      "metadata": {
        "id": "E2AfKoKkknSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-classification\",model=\"roberta-large-mnli\")\n",
        "pipe(\"A soccer game with multiple males playing., Some men are playing a sport\")"
      ],
      "metadata": {
        "id": "-O0hS_K5vonm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Natural Language Inference (QNLI)\n",
        "The QNLI task involves determining whether a given question can be answered by the information in a provided document. If the answer can be found in the document, the label assigned is \"entailment\". Conversely, if the answer cannot be found in the document, the label assigned is \"not entailment\".\n",
        "\n",
        "If you want to use an QNLI model, you can find them on the ü§ó Hugging Face model hub. Look for models with \"qnli\"."
      ],
      "metadata": {
        "id": "lTps9NAXlFHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-classification\",model=\"cross-encoder/qnli-electra-base\")\n",
        "pipe(\"Who was the London Weekend Television‚Äôs Managing Director?,The managing director of London Weekend Television (LWT), Greg Dyke, met with the representatives of the \\\"big five\\\" football clubs in England in 1990.\")\n"
      ],
      "metadata": {
        "id": "F0P6tVL1yBss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quora Question Pairs (QQP)\n",
        "The Quora Question Pairs model is designed to evaluate whether two given questions are paraphrases of each other. This model takes the two questions and assigns a binary value as output. LABEL_0 indicates that the questions are paraphrases of each other and LABEL_1 indicates that the questions are not paraphrases. The benchmark dataset used for this task is the Quora Question Pairs dataset within the GLUE benchmark, which contains a collection of question pairs and their corresponding labels.\n",
        "\n",
        "If you want to use an QQP model, you can find them on the ü§ó Hugging Face model hub. Look for models with qqp."
      ],
      "metadata": {
        "id": "m404MRnblTf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-classification\", model = \"textattack/bert-base-uncased-QQP\")\n",
        "pipe(\"Which city is the capital of France?, Where is the capital of France?\")"
      ],
      "metadata": {
        "id": "lehE_8wTy3Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grammatical Correctness\n",
        "Linguistic Acceptability is a task that involves evaluating the grammatical correctness of a sentence. The model used for this task assigns one of two classes to the sentence, either \"acceptable\" or \"unacceptable\". LABEL_0 indicates acceptable and LABEL_1 indicates unacceptable. The benchmark dataset used for training and evaluating models for this task is the Corpus of Linguistic Acceptability (CoLA), which consists of a collection of texts along with their corresponding labels.\n",
        "\n",
        "If you want to use a grammatical correctness model, you can find them on the ü§ó Hugging Face model hub. Look for models with cola."
      ],
      "metadata": {
        "id": "qOwN5PjCli4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-classification\", model = \"textattack/distilbert-base-uncased-CoLA\")\n",
        "pipe(\"I will walk to home when I went through the bus.\")"
      ],
      "metadata": {
        "id": "gCgqMU2RzPpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot Classification\n",
        "\n",
        "Zero Shot Classification is a task where the model predicts a class that it hasn't seen during the training phase. This task leverages a pre-trained language model and is a type of transfer learning. Transfer learning involves using a model that was initially trained for one task in a different application. Zero Shot Classification is especially helpful when there is a scarcity of labeled data available for the specific task at hand."
      ],
      "metadata": {
        "id": "3fP-pJEkl6qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(task=\"zero-shot-classification\",model=\"facebook/bart-large-mnli\")\n",
        "text_to_classify= \"I have a problem with my iphone that needs to be resolved asap!!\"\n",
        "candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"]\n",
        "classifier(text_to_classify, candidate_labels, multi_label=True)\n"
      ],
      "metadata": {
        "id": "ydUatJEW10IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token Classification\n",
        "\n",
        "Token classification is a task in natural language understanding, where labels are assigned to certain tokens in a text. Some popular subtasks of token classification include Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging. NER models can be trained to identify specific entities in a text, such as individuals, places, and dates. PoS tagging, on the other hand, is used to identify the different parts of speech in a text, such as nouns, verbs, and punctuation marks."
      ],
      "metadata": {
        "id": "ara--JU4mquj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Named Entity Recognition\n",
        "Named Entity Recognition (NER) is a task that involves identifying named entities in a text. These entities can include the names of people, locations, or organizations. The task is completed by labeling each token with a class for each named entity and a class named \"0\" for tokens that don't contain any entities. In this task, the input is text, and the output is the annotated text with named entities."
      ],
      "metadata": {
        "id": "CPVGVBUfmuAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"token-classification\")\n",
        "pipe(\"I am John and I live in New York City.\")\n"
      ],
      "metadata": {
        "id": "PHv5ULjSX3lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-of-Speech (PoS) Tagging\n",
        "PoS tagging is a task that involves identifying the parts of speech, such as nouns, pronouns, adjectives, or verbs, in a given text. In this task, the model labels each word with a specific part of speech.\n",
        "\n",
        "Look for models with pos to use a zero-shot classification model on the ü§ó Hugging Face model hub."
      ],
      "metadata": {
        "id": "eFNaJnTHnDXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"token-classification\", model=\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
        "pipe(\"I am George and I live in Phoenix.\")"
      ],
      "metadata": {
        "id": "_rNFe5FEY_rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation\n",
        "Translation is the task of converting text written in one language into another language. You have the option to select from over 2000 models available on the Hugging Face hub for translation."
      ],
      "metadata": {
        "id": "zdGbPMCwni1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"translation_en_to_fr\")\n",
        "pipe(\"How are you?\")"
      ],
      "metadata": {
        "id": "xKVB4ZYrZ8nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization\n",
        "\n",
        "Summarization involves creating a condensed version of a document that includes the important information while reducing its length. Different models can be used for this task, with some models extracting the most relevant text from the original document, while other models generate completely new text that captures the essence of the original content."
      ],
      "metadata": {
        "id": "Q7RqcPpOnsfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"\n",
        "The unanimous Declaration of the thirteen united States of America, When in the Course of human events, it becomes necessary for one people to dissolve the political bands which have connected them with another, and to assume among the powers of the earth, the separate and equal station to which the Laws of Nature and of Nature's God entitle them, a decent respect to the opinions of mankind requires that they should declare the causes which impel them to the separation.\n",
        "\n",
        "We hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.--That to secure these rights, Governments are instituted among Men, deriving their just powers from the consent of the governed, --That whenever any Form of Government becomes destructive of these ends, it is the Right of the People to alter or to abolish it, and to institute new Government, laying its foundation on such principles and organizing its powers in such form, as to them shall seem most likely to effect their Safety and Happiness. Prudence, indeed, will dictate that Governments long established should not be changed for light and transient causes; and accordingly all experience hath shewn, that mankind are more disposed to suffer, while evils are sufferable, than to right themselves by abolishing the forms to which they are accustomed. But when a long train of abuses and usurpations, pursuing invariably the same Object evinces a design to reduce them under absolute Despotism, it is their right, it is their duty, to throw off such Government, and to provide new Guards for their future security.--Such has been the patient sufferance of these Colonies; and such is now the necessity which constrains them to alter their former Systems of Government. The history of the present King of Great Britain is a history of repeated injuries and usurpations, all having in direct object the establishment of an absolute Tyranny over these States. To prove this, let Facts be submitted to a candid world.\n",
        "\"\"\"\n",
        "print(len(document.split()))\n",
        "pipe = pipeline(task=\"summarization\")\n",
        "pipe(document)"
      ],
      "metadata": {
        "id": "_8qwD7g9ck-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Answering\n",
        "Question Answering models are designed to retrieve the answer to a question from a given text, which can be particularly useful for searching for information within a document. It's worth noting that some question answering models are capable of generating answers even without any contextual information."
      ],
      "metadata": {
        "id": "tyaaD3HvoFYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_model = pipeline(\"question-answering\")\n",
        "question = \"Where do I live?\"\n",
        "context = \"My name is Merve and I live in ƒ∞stanbul.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "id": "ukijW6KMjjP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation\n",
        "\n",
        "This is a task of producing new text. These models can, for example, fill in incomplete text or paraphrase."
      ],
      "metadata": {
        "id": "gdccvIk9rlcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline('text-generation', model = 'gpt2')\n",
        "output = generator(\"Hello, I'm a language model\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "mDLbHaIoeThW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-context Learning\n",
        "In-context learning (ICL) is a specific method of prompt engineering where demonstrations of the task are provided to the model as part of the prompt (in natural language). With ICL, you can use off-the-shelf large language models (LLMs) to solve novel tasks without the need for fine-tuning. In the below example, you will learn how to perform Named Entity Recognition using few-shot examples."
      ],
      "metadata": {
        "id": "_o3-tUz0sAOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "prompt = \"\"\"\n",
        "Extract the main person and place from a sentence:\n",
        "\n",
        "###\n",
        "Paul is playing football in New York with Heather.\n",
        "Person: Paul, Place: New York, Person: Heather\n",
        "###\n",
        "Jeff is in a hurry to go to Boston.\n",
        "Person: Jeff, Place: Boston\n",
        "###\n",
        "Max is going to Phildelphia.\n",
        "Person: Max, Place: Philadelphia\n",
        "###\n",
        "Sam is from Phoenix\n",
        "\"\"\"\n",
        "model_name = 'gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "device = 'cuda:0'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(input_ids=input_ids, do_sample=True, max_new_tokens=10, temperature=0.01, eos_token_id=tokenizer.encode(\"###\"), pad_token_id = tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0][len(input_ids[0]):-1]))"
      ],
      "metadata": {
        "id": "GawJSETmsA1L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}